<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Simon Willison's Weblog (中文)</title><link>http://simonwillison.net/</link><description/><language>zh-CN</language><lastBuildDate>Mon, 09 Feb 2026 23:56:51 +0000</lastBuildDate><item><title>面向文件原生智能体系统的结构化情境工程</title><link>https://simonwillison.net/2026/Feb/9/structured-context-engineering-for-file-native-agentic-systems/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2602.05447"&gt;面向文件原生智能体系统的结构化上下文工程&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;Damon McMillan发表新论文，探索涉及大规模SQL架构（高达10,000张表）的LLM上下文挑战性任务，涵盖不同模型与文件格式：
&lt;blockquote&gt;
&lt;p&gt;我们以SQL生成为程序化智能体操作的代理指标，对结构化数据的上下文工程展开系统性研究，涵盖11种模型、4种格式（YAML、Markdown、JSON、面向令牌的对象标记法[TOON]）以及10至10,000张表的架构，累计完成9,649次实验。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不出所料，模型本身的影响最为显著——前沿模型（Opus 4.5、GPT-5.2、Gemini 2.5 Pro）的表现优于领先的开源模型（DeepSeek V3.2、Kimi K2、Llama 4）。&lt;/p&gt;
&lt;p&gt;这些前沿模型受益于基于文件系统的上下文检索，但开源模型在此方面的表现远未达预期，这印证了我的观点：开源权重模型目前尚未充分掌握文件系统编码智能体的循环处理机制。&lt;a href="https://www.tbench.ai/leaderboard/terminal-bench/2.0"&gt;Terminal Bench 2.0&lt;/a&gt;排行榜仍由Anthropic、OpenAI和Gemini主导。&lt;/p&gt;
&lt;p&gt;针对&lt;a href="https://github.com/toon-format/toon"&gt;TOON格式&lt;/a&gt;的“检索代价”现象是个有趣的细节。TOON旨在以最少令牌数呈现结构化数据，但研究发现模型对该格式的陌生导致其在多次迭代中消耗显著更多令牌以尝试解析：&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot of a figure from a research paper. Introductory text reads: &amp;quot;As schema size increased, TOON showed dramatically increased token consumption for Claude models despite being ~25% smaller in file size. Scale experiments used Claude models only.&amp;quot; Below is &amp;quot;Figure 7: The 'Grep Tax' - TOON Token Overhead at Scale&amp;quot;, a bar chart with a logarithmic y-axis labeled &amp;quot;Tokens&amp;quot; comparing YAML (teal) and TOON (purple) at two schema sizes: S5 (500 tables) and S9 (10,000 tables). At S5, TOON is +138% more tokens than YAML (~1,100 vs ~450). At S9, TOON is +740% more tokens (~50,000 vs ~7,000). Below the chart, explanatory text reads: &amp;quot;The 'grep tax' emerged as schema size scaled. At S5 (500 tables), TOON consumed 138% more tokens than YAML; at S9 (10,000 tables), this grew to 740%. Root cause: models lacked familiarity with TOON's syntax and could not construct effective refinement patterns.&amp;quot;" src="https://static.simonwillison.net/static/2026/grep-tax.jpg"/&gt;
&lt;p&gt;&lt;small&gt;&lt;/small&gt;经由&lt;a href="https://twitter.com/omarsar0/status/2020150077637997013"&gt;@omarsar0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/ai"&gt;人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/prompt-engineering"&gt;提示工程&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/generative-ai"&gt;生成式人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/llms"&gt;大语言模型&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/paper-review"&gt;论文评述&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/context-engineering"&gt;上下文工程&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Mon, 09 Feb 2026 23:56:51 +0000</pubDate></item><item><title>AI不减负，反而增负</title><link>https://simonwillison.net/2026/Feb/9/ai-intensifies-work/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it"&gt;AI并未减轻工作负担，反而加剧了工作强度&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;伯克利哈斯商学院的阿鲁娜·兰加纳特和邢琪·玛吉·叶在《哈佛商业评论》上发表了初步研究结果，该研究于2025年4月至12月对一家"美国科技公司"的200名员工展开。
&lt;p&gt;这印证了我在使用大语言模型工作中观察到的现象：这些工具带来的生产力提升&lt;em&gt;令人精疲力竭&lt;/em&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI引入了新的工作节奏：员工同时处理多个任务线程——手动编写代码时AI同步生成替代版本、并行运行多个智能体、或是重启长期搁置的任务只因AI能在后台"处理它们"。部分原因是他们感觉有了能协助推进工作的"合作伙伴"。&lt;/p&gt;
&lt;p&gt;虽然这种"合作伙伴"感带来了前进动力，但现实却是注意力的持续切换、对AI输出的频繁检查以及不断增多的待办事项。即使工作看似高效，却造成了认知负荷和始终疲于奔命的感觉。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我经常发现自己同时推进两三个项目。虽然能&lt;em&gt;完成大量工作&lt;/em&gt;，但仅一两个小时后，当天的脑力就几乎消耗殆尽。&lt;/p&gt;
&lt;p&gt;最近与一些人的交流中发现，他们正因难以抗拒"再输入一条指令就能构建新功能"的诱惑而失眠。&lt;/p&gt;
&lt;p&gt;《哈佛商业评论》文章呼吁企业建立"AI实践规范"，构建AI使用框架以避免职业倦怠，并抵制那些"让企业难以区分真实生产力提升与不可持续强度"的效应。&lt;/p&gt;
&lt;p&gt;我认为我们刚刚颠覆了数十年来关于可持续工作模式的固有认知。要找到新的良好平衡点，尚需时日与规则约束。&lt;p&gt;&lt;small&gt;&lt;/small&gt;来源&lt;a href="https://news.ycombinator.com/item?id=46945755"&gt;黑客新闻&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/careers"&gt;职业生涯&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai"&gt;人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/generative-ai"&gt;生成式AI&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/llms"&gt;大语言模型&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;AI辅助编程&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;AI伦理&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Mon, 09 Feb 2026 16:43:07 +0000</pubDate></item><item><title>卡卡波马克杯，凯伦·詹姆斯设计</title><link>https://simonwillison.net/2026/Feb/8/kakapo-mug/#atom-everything</link><description>&lt;p&gt;朋友兼邻居凯伦·詹姆斯送了我一个鸮鹦鹉马克杯。杯身绘有一只神气活现的鸮鹦鹉和四只雏鸟（庆祝2026年繁殖季），甚至还点缀着芮木浆果图案！我实在太喜欢了。

标签：鸮鹦鹉，艺术&lt;a href="https://www.etsy.com/shop/KarenJamesMakes"&gt;Karen James&lt;/a&gt; made me a Kākāpō mug. It has a charismatic Kākāpō, four Kākāpō chicks (in celebration of the &lt;a href="https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-k-k-p-parrots-will-have-an-outstanding-breeding-season"&gt;2026 breeding season&lt;/a&gt;) and even has some &lt;a href="https://www.theguardian.com/world/2026/jan/13/nz-kakapo-mating-season"&gt;rimu fruit&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img alt="A simply spectacular sgraffito ceramic mug with a bold, charismatic Kākāpō parrot taking up most of the visible space. It has a yellow beard and green feathers." src="https://static.simonwillison.net/static/2026/kakapo-mug-1.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Another side of the mug, two cute grey Kākāpō chicks are visible and three red rimu fruit that look like berries, one on the floor and two hanging from wiry branches." src="https://static.simonwillison.net/static/2026/kakapo-mug-2.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;I love it so much.&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/kakapo"&gt;kakapo&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/art"&gt;art&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 08 Feb 2026 17:25:07 +0000</pubDate></item><item><title>引用托马斯·普塔切克的话</title><link>https://simonwillison.net/2026/Feb/8/thomas-ptacek/#atom-everything</link><description>&lt;blockquote cite="https://twitter.com/tqbf/status/2019493645888462993"&gt;&lt;p&gt;橙色网站上的人们对此嗤之以鼻，认为这只是广告宣传，没什么实质内容。但我接触的漏洞研究人员并不觉得这是个玩笑。作为曾经的漏洞研究者，我想说：别低估大语言模型在这方面的能力。

Axios报道：Anthropic的Claude Opus 4.6在开源项目中发现了500个零日漏洞

我认为漏洞研究可能是最适合大语言模型解决的软件工程问题。它具有模式驱动、海量公开操作模式库、闭环系统、工具链刺激响应推动进展、搜索问题等特点。

前沿实验室的模型卡片里就记录着漏洞研究成果。这些公司资金雄厚，甚至能影响经济走向。资金可以买来漏洞研究成果，凭什么认为他们需要造假呢？

——
托马斯·普塔切克

标签：
托马斯-普塔切克，
Anthropic，
Claude，
安全，
生成式AI，
人工智能，
大语言模型，
开源&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.axios.com/2026/02/05/anthropic-claude-opus-46-software-hunting"&gt;Axios: Anthropic's Claude Opus 4.6 uncovers 500 zero-day flaws in open-source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I think vulnerability research might be THE MOST LLM-amenable software engineering problem. Pattern-driven. Huge corpus of operational public patterns. Closed loops. Forward progress from stimulus/response tooling. Search problems.&lt;/p&gt;
&lt;p&gt;Vulnerability research outcomes are in THE MODEL CARDS for frontier labs. Those companies have so much money they're literally distorting the economy. Money buys vuln research outcomes. Why would you think they were faking any of this?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;— &lt;a href="https://twitter.com/tqbf/status/2019493645888462993"&gt;Thomas Ptacek&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/thomas-ptacek"&gt;thomas-ptacek&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/anthropic"&gt;anthropic&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude"&gt;claude&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/security"&gt;security&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/open-source"&gt;open-source&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 08 Feb 2026 02:25:53 +0000</pubDate></item><item><title>担保</title><link>https://simonwillison.net/2026/Feb/7/vouch/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/mitchellh/vouch"&gt;担保&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;随着开源项目贡献门槛大幅降低，米切尔·哈希莫尼推出新系统应对海量无价值AI生成PR的冲击。
&lt;p&gt;&lt;a href="https://twitter.com/mitchellh/status/2020252149117313349"&gt;他表示&lt;/a&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;核心理念简明：未获担保用户无法向项目提交贡献。劣质用户可被明确“标记”，实质封禁。担保与标记机制通过GitHub议题讨论区评论或CLI由贡献者执行。&lt;/p&gt;
&lt;p&gt;集成至GitHub仅需采用官方发布的GitHub Actions即可完成。该系统本身具备平台通用性，与GitHub无强制绑定。&lt;/p&gt;
&lt;p&gt;担保标准与执行方式由各项目自主决定。我不充当全球价值警察。请根据项目与社区特性自行制定规则。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/open-source"&gt;开源&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai"&gt;人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/github-actions"&gt;GitHub-Actions&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/generative-ai"&gt;生成式AI&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/mitchell-hashimoto"&gt;米切尔-哈希莫尼&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;AI伦理&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sat, 07 Feb 2026 23:57:57 +0000</pubDate></item><item><title>Claude：使用快速模式加速响应</title><link>https://simonwillison.net/2026/Feb/7/claude-fast-mode/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://code.claude.com/docs/en/fast-mode"&gt;Claude：快速模式加速响应&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;Anthropic今日推出全新“研究预览版”：现在通过在Claude Code中输入&lt;code&gt;/fast&lt;/code&gt;即可访问其前沿模型Claude Opus 4.6的加速版本...但价格是常规模式的6倍
&lt;p&gt;Opus常规定价为输入每百万token 5美元/输出每百万token 25美元。全新快速模式定价飙升至输入每百万token 30美元/输出每百万token 150美元！&lt;/p&gt;
&lt;p&gt;2月16日前享受5折优惠，届时价格倍数将降至3倍（！）&lt;/p&gt;
&lt;p&gt;速度提升多少？官方文档未明确说明，但&lt;a href="https://x.com/claudeai/status/2020207322124132504"&gt;在推特平台&lt;/a&gt;Claude团队透露：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们内部测试的Claude Opus 4.6版本已实现2.5倍加速&lt;/p&gt;
&lt;p&gt;现通过Claude Code和API作为早期实验功能开放&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Claude Opus 4.5支持20万token上下文。4.6版本提供扩展至100万token的选项，当输入超过20万token时，输入价格翻倍至每百万token 10美元，输出价格增至1.5倍达每百万token 37.5美元。该倍数体系同样适用于快速模式，这意味着2月16日后，为获得Anthropic最快最强的模型，用户需支付高达输入每百万token 60美元/输出每百万token 225美元的费用&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/ai"&gt;人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/generative-ai"&gt;生成式人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/llms"&gt;大语言模型&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/anthropic"&gt;Anthropic&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/claude"&gt;Claude&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/llm-pricing"&gt;大语言模型定价&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/claude-code"&gt;Claude代码&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Sat, 07 Feb 2026 23:10:33 +0000</pubDate></item><item><title>引用大卫·克劳肖的话</title><link>https://simonwillison.net/2026/Feb/7/david-crawshaw/#atom-everything</link><description>&lt;blockquote cite="https://crawshaw.io/blog/eight-more-months-of-agents"&gt;&lt;p&gt;我比以往任何时候都更享受编程的乐趣，因为那些我曾希望有时间编写的程序，如今大多已成现实。我希望能与那些对智能体带来的变革感到担忧的人们分享这份喜悦。我理解这种恐惧——对于智能技术在我们社会中最终将走向何方，我也有着更广泛的忧虑。但就编写计算机程序这一有限领域而言，这些工具为我的工作带来了如此多的探索与快乐。

——
大卫·克劳肖
，《智能体再启八个月》
标签：
编程智能体
、
AI辅助编程
、
生成式AI
、
人工智能
、
大语言模型&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;— &lt;a href="https://crawshaw.io/blog/eight-more-months-of-agents"&gt;David Crawshaw&lt;/a&gt;, Eight more months of agents&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sat, 07 Feb 2026 21:31:44 +0000</pubDate></item><item><title>StrongDM的AI团队如何在不看代码的情况下构建重要软件</title><link>https://simonwillison.net/2026/Feb/7/software-factory/#atom-everything</link><description>&lt;p&gt;上周我提到过一个团队演示，他们实现了丹·夏皮罗所说的"暗黑工厂"级AI应用——人类甚至无需查看编码智能体生成的代码。该团队来自StrongDM公司，他们刚刚首次公开描述了如何在"软件工厂与智能体时刻"中开展工作：

我们构建了"软件工厂"：这是一种非交互式开发模式，由需求规格和场景驱动智能体编写代码、运行测试框架并自动收敛，全程无需人工审核。[...]

以禅语或箴言形式呈现：
为何由我动手？（潜台词：这该由模型代劳）

以规则形式呈现：
代码必须不由人类编写
代码必须不经人类审核

最终以实践形式呈现：
若团队每位人类工程师当日令牌开销未达1000美元，则说明你的软件工厂尚有改进空间

我认为其中最耐人寻味的无疑是"代码必须不经人类审核"。当我们都清楚大语言模型多么容易犯非人类错误时，这怎么可能成为合理策略？

近来我注意到许多开发者开始认同"2025年11月拐点"——当Claude Opus 4.5和GPT 5.2出现时，编码智能体在遵循指令和执行复杂编码任务方面的可靠性发生了质变。StrongDM的AI团队其实早在2025年7月就已成立，其契机是更早的Claude Sonnet 3.5带来的转折：

催化剂是2024年末观察到的转变：随着Claude 3.5第二次版本迭代（2024年10月），长周期智能体编码工作流开始累积正确性而非错误。到2024年12月，通过Cursor的"YOLO模式"已能清晰见证模型在长周期编码任务中的卓越表现。

这个新团队创立时便立下"杜绝手工编码"的准则——这在2025年7月堪称激进，但据我观察，截至2026年1月已有大量资深开发者开始采纳这种模式。&lt;a href="https://simonwillison.net/2026/Jan/28/the-five-levels/"&gt;I hinted at&lt;/a&gt; a demo I had seen from a team implementing what Dan Shapiro called &lt;a href="https://www.danshapiro.com/blog/2026/01/the-five-levels-from-spicy-autocomplete-to-the-software-factory/"&gt;the Dark Factory&lt;/a&gt; level of AI adoption, where no human even looks at the code the coding agents are producing. That team was part of StrongDM, and they've just shared the first public description of how they are working in &lt;a href="https://factory.strongdm.ai"&gt;Software Factories and the Agentic Moment&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We built a &lt;strong&gt;Software Factory&lt;/strong&gt;: non-interactive development where specs + scenarios drive agents that write code, run harnesses, and converge without human review. [...]&lt;/p&gt;
&lt;p&gt;In kōan or mantra form:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why am I doing this? (implied: the model should be doing this instead)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In rule form:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code &lt;strong&gt;must not be&lt;/strong&gt; written by humans&lt;/li&gt;
&lt;li&gt;Code &lt;strong&gt;must not be&lt;/strong&gt; reviewed by humans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, in practical form:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you haven't spent at least &lt;strong&gt;$1,000 on tokens today&lt;/strong&gt; per human engineer, your software factory has room for improvement&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think the most interesting of these, without a doubt, is "Code &lt;strong&gt;must not be&lt;/strong&gt; reviewed by humans". How could that &lt;em&gt;possibly&lt;/em&gt; be a sensible strategy when we all know how prone LLMs are to making &lt;a href="https://simonwillison.net/2025/Mar/2/kellan-elliott-mccrea/"&gt;inhuman mistakes&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;I've seen many developers recently acknowledge the &lt;a href="https://simonwillison.net/2026/Jan/4/inflection/"&gt;November 2025 inflection point&lt;/a&gt;, where Claude Opus 4.5 and GPT 5.2 appeared to turn the corner on how reliably a coding agent could follow instructions and take on complex coding tasks. StrongDM's AI team was founded in July 2025 based on an earlier inflection point relating to Claude Sonnet 3.5:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The catalyst was a transition observed in late 2024: with the second revision of Claude 3.5 (October 2024), long-horizon agentic coding workflows began to compound correctness rather than error.&lt;/p&gt;
&lt;p&gt;By December of 2024, the model's long-horizon coding performance was unmistakable via Cursor's &lt;a href="https://forum.cursor.com/t/yolo-mode-is-amazing/36262"&gt;YOLO mode&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Their new team started with the rule "no hand-coded software" - radical for July 2025, but something I'm seeing significant numbers of experienced developers start to adopt as of January 2026.&lt;/p&gt;
&lt;p&gt;他们很快遇到了一个显而易见的问题：如果不亲手编写任何代码，如何确保代码真正有效？让智能体编写测试只能在不作弊的前提下提供帮助。

这或许是当前软件开发中最关键的问题：当代码实现和测试用例都由编程智能体代劳时，如何证明你正在开发的软件确实能正常运行？

StrongDM的解决方案灵感来源于场景测试理论。他们这样描述其方法：

我们重新定义了"场景"一词，用它来代表端到端的"用户故事"。这些场景通常存储在代码库之外，类似于模型训练中的"保留集"，能够被大语言模型直观理解并进行灵活验证。

由于我们开发的软件本身具有智能体特性，我们将成功标准从布尔判定转变为概率化实证评估。我们使用"满意度"来量化验证结果：在所有场景观察到的运行轨迹中，有多少比例可能满足用户需求？

将场景视为保留集——用于评估软件却不让编程智能体接触——这个构想令人着迷。它模拟了外部质量保证团队进行的严格测试，这种传统软件质量保障方式虽然成本高昂却极为有效。

这引出了StrongDM的"数字孪生宇宙"概念，也是演示中最令我印象深刻的部分。

他们正在开发的软件用于管理跨平台服务的用户权限。这本身就值得关注——安全软件本应是最不可能使用未经审查的大语言模型代码构建的领域！

数字孪生宇宙是我们软件所依赖第三方服务的行为克隆体。我们构建了Okta、Jira、Slack、Google文档、Google云端硬盘和Google表格的数字孪生，完整复现了它们的应用程序接口、边界情况和可观测行为。&lt;code&gt;assert true&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This feels like the most consequential question in software development right now: how can you &lt;a href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/"&gt;prove that software you are producing works&lt;/a&gt; if both the implementation and the tests are being written for you by coding agents?&lt;/p&gt;
&lt;p&gt;StrongDM's answer was inspired by &lt;a href="https://en.wikipedia.org/wiki/Scenario_testing"&gt;Scenario testing&lt;/a&gt; (Cem Kaner, 2003). As StrongDM describe it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We repurposed the word &lt;strong&gt;scenario&lt;/strong&gt; to represent an end-to-end "user story", often stored outside the codebase (similar to a "holdout" set in model training), which could be intuitively understood and flexibly validated by an LLM.&lt;/p&gt;
&lt;p&gt;Because much of the software we grow itself has an agentic component, we transitioned from boolean definitions of success ("the test suite is green") to a probabilistic and empirical one. We use the term &lt;strong&gt;satisfaction&lt;/strong&gt; to quantify this validation: of all the observed trajectories through all the scenarios, what fraction of them likely satisfy the user?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That idea of treating scenarios as holdout sets - used to evaluate the software but not stored where the coding agents can see them - is &lt;em&gt;fascinating&lt;/em&gt;. It imitates aggressive testing by an external QA team - an expensive but highly effective way of ensuring quality in traditional software.&lt;/p&gt;
&lt;p&gt;Which leads us to StrongDM's concept of a &lt;strong&gt;Digital Twin Universe&lt;/strong&gt; - the part of the demo I saw that made the strongest impression on me.&lt;/p&gt;
&lt;p&gt;The software they were building helped manage user permissions across a suite of connected services. This in itself was notable - security software is the last thing you would expect to be built using unreviewed LLM code!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[The Digital Twin Universe is] behavioral clones of the third-party services our software depends on. We built twins of Okta, Jira, Slack, Google Docs, Google Drive, and Google Sheets, replicating their APIs, edge cases, and observable behaviors.&lt;/p&gt;
&lt;p&gt;借助DTU，我们能够以远超生产限制的规模和速率进行验证。我们可以测试那些针对真实服务既危险又无法实施的故障模式。每小时运行数千个场景，既不会触及速率限制、触发滥用检测，也不会累积API成本。

如何克隆Okta、Jira、Slack等系统的核心部分？答案是：借助编码智能体！

据我理解，其诀窍在于将某个服务的完整公开API文档导入智能体框架，让它构建一个自包含的Go二进制文件来模拟该API。随后还能在此基础上构建简化版用户界面，以完善整个模拟系统。

最新动态：DTU创建者Jay Taylor在Hacker News上分享了更多背景信息，并透露了一项关键提示策略：

"我最初获得了一个关键洞见，由此形成了一套可复现的策略，确保DTU与官方标准SaaS服务之间保持高度保真度。"

通过建立独立于原服务的克隆系统——摆脱速率限制和使用配额——他们的模拟测试大军得以展开无拘无束的测试。场景测试脚本成为智能体持续验证新建系统的行动指南。

这张Slack孪生系统的截图生动展示了测试流程：模拟Okta用户流即将接入不同模拟系统的实时画面。

快速构建Slack核心功能克隆体的能力，充分展现了新一代编码智能体工具的颠覆性潜力：

创建高保真度的重量级SaaS应用克隆体在技术上始终可行，但经济层面从未具备可行性。历代工程师或许都曾渴望建立完整的CRM内存副本用于测试，却始终自我否定了构建提案。

他们的技术文档页面同样值得关注。除了数字孪生宇宙概念，还引入了"基因输注"等创新术语。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;How do you clone the important parts of Okta, Jira, Slack and more? With coding agents!&lt;/p&gt;
&lt;p&gt;As I understood it the trick was effectively to dump the full public API documentation of one of those services into their agent harness and have it build an imitation of that API, as a self-contained Go binary. They could then have it build a simplified UI over the top to help complete the simulation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: DTU creator Jay Taylor posted some extra context about this &lt;a href="https://news.ycombinator.com/item?id=46924426#46931812"&gt;on Hacker News&lt;/a&gt; sharing a key prompting strategy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I did have an initial key insight which led to a repeatable strategy to ensure a high level of fidelity between DTU vs. the official canonical SaaS services:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Use the top popular publicly available reference SDK client libraries as compatibility targets, with the goal always being 100% compatibility.&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With their own, independent clones of those services - free from rate-limits or usage quotas - their army of simulated testers could go &lt;em&gt;wild&lt;/em&gt;. Their scenario tests became scripts for agents to constantly execute against the new systems as they were being built.&lt;/p&gt;
&lt;p&gt;This screenshot of their Slack twin also helps illustrate how the testing process works, showing a stream of simulated Okta users who are about to need access to different simulated systems.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot of a Slack-like interface titled &amp;quot;DTU Slack&amp;quot; showing a thread view (Thread — C4B9FBB97) with &amp;quot;Focus first&amp;quot; and &amp;quot;Leave&amp;quot; buttons. The left sidebar lists channels including # org-general (182), # general (0) (shared×2), # it-support (0), # channel-0002 (0) (shared×2), # channel-0003 (0) through # channel-0020 (0), # org-finance (1), and a DMs section with a &amp;quot;Start&amp;quot; button. A &amp;quot;Create&amp;quot; button appears at the top of the sidebar. The main thread shows approximately 9 automated introduction messages from users with Okta IDs (e.g. @okta-u-423438-00001, @okta-u-423438-00002, etc.), all timestamped 2025-11-12Z between 18:50:31 and 18:51:51. Each message follows the format &amp;quot;Hi team! I'm [Name], joining as Employee in general. Key skills: [fictional skill phrases]. Excited to contribute!&amp;quot; All users have red/orange &amp;quot;O&amp;quot; avatar icons." src="https://static.simonwillison.net/static/2026/strong-dm-slack.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;This ability to quickly spin up a useful clone of a subset of Slack helps demonstrate how disruptive this new generation of coding agent tools can be:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Creating a high fidelity clone of a significant SaaS application was always possible, but never economically feasible. Generations of engineers may have &lt;em&gt;wanted&lt;/em&gt; a full in-memory replica of their CRM to test against, but self-censored the proposal to build it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href="https://factory.strongdm.ai/techniques"&gt;techniques page&lt;/a&gt; is worth a look too. In addition to the Digital Twin Universe they introduce terms like &lt;strong&gt;&lt;a href="https://factory.strongdm.ai/techniques/gene-transfusion"&gt;Gene Transfusion&lt;/a&gt;&lt;/strong&gt;让智能体从现有系统中提取模式并在其他地方复用，  
**Semports**  
用于直接将代码从一种语言移植到另一种语言，  
**Pyramid Summaries**  
提供多层级摘要，使智能体能快速浏览简短版本，并在需要时深入查看更详细信息。  

StrongDM AI 还以非传统的方式发布了一些软件。  
**github.com/strongdm/attractor**  
是 **Attractor**，他们软件工厂的核心非交互式编码智能体。但这个仓库本身没有任何代码——只有三个 Markdown 文件，详细描述了软件规范，并在 README 中注明：你应该将这些规范输入你选择的编码智能体！  

**github.com/strongdm/cxdb**  
则是一个更传统的发布，包含 16,000 行 Rust 代码、9,500 行 Go 代码和 6,700 行 TypeScript 代码。这是他们的“AI 上下文存储”——一个用于在不可变有向无环图中存储对话历史和工具输出的系统。  
它类似于我的 LLM 工具的 **SQLite 日志机制**，但复杂得多。我可能需要从中汲取一些灵感！  

**未来的缩影？**  
去年十月，我作为受邀嘉宾之一拜访了 StrongDM AI 团队。  
Justin McCarthy、Jay Taylor 和 Navan Chauhan 三人团队仅成立三个月，就已经展示了他们的编码智能体框架、多个服务的数字孪生克隆，以及模拟测试智能体运行场景的演示。而这些演示是在 Opus 4.5/GPT 5.2 发布之前进行的——一个月后，这些版本使智能体编码的可靠性显著提升。  
这仿佛瞥见了软件开发的一种潜在未来：软件工程师从编写代码转向构建并半监控那些生成代码的系统。  
**黑暗工厂**。  

等等，每个工程师每天 1,000 美元？&lt;strong&gt;&lt;a href="https://factory.strongdm.ai/techniques/semport"&gt;Semports&lt;/a&gt;&lt;/strong&gt; for directly porting code from one language to another and &lt;strong&gt;&lt;a href="https://factory.strongdm.ai/techniques/pyramid-summaries"&gt;Pyramid Summaries&lt;/a&gt;&lt;/strong&gt; for providing multiple levels of summary such that an agent can enumerate the short ones quickly and zoom in on more detailed information as it is needed.&lt;/p&gt;
&lt;p&gt;StrongDM AI also released some software - in an appropriately unconventional manner.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/strongdm/attractor"&gt;github.com/strongdm/attractor&lt;/a&gt; is &lt;strong&gt;Attractor&lt;/strong&gt;, the non-interactive coding agent at the heart of their software factory. Except the repo itself contains no code at all - just three markdown files describing the spec for the software in meticulous detail, and a note in the README that you should feed those specs into your coding agent of choice!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/strongdm/cxdb"&gt;github.com/strongdm/cxdb&lt;/a&gt; is a more traditional release, with 16,000 lines of Rust, 9,500 of Go and 6,700 of TypeScript. This is their "AI Context Store" - a system for storing conversation histories and tool outputs in an immutable DAG.&lt;/p&gt;
&lt;p&gt;It's similar to my LLM tool's &lt;a href="https://llm.datasette.io/en/stable/logging.html#sql-schema"&gt;SQLite logging mechanism&lt;/a&gt; but a whole lot more sophisticated. I may have to gene transfuse some ideas out of this one!&lt;/p&gt;
&lt;h4 id="a-glimpse-of-the-future-"&gt;A glimpse of the future?&lt;/h4&gt;
&lt;p&gt;I visited the StrongDM AI team back in October as part of a small group of invited guests.&lt;/p&gt;
&lt;p&gt;The three person team of Justin McCarthy, Jay Taylor and Navan Chauhan had formed just three months earlier, and they already had working demos of their coding agent harness, their Digital Twin Universe clones of half a dozen services and a swarm of simulated test agents running through scenarios. And this was prior to the Opus 4.5/GPT 5.2 releases that made agentic coding significantly more reliable a month after those demos.&lt;/p&gt;
&lt;p&gt;It felt like a glimpse of one potential future of software development, where software engineers move from building the code to building and then semi-monitoring the systems that build the code. The Dark Factory.&lt;/p&gt;
&lt;h4 id="wait-1-000-day-per-engineer-"&gt;Wait, $1,000/day per engineer?&lt;/h4&gt;
&lt;p&gt;我在最初发布的版本中略过了这个细节，但它确实值得认真关注。

如果这些模式真的会让你的预算每月为每位工程师增加两万美元，那它们对我的吸引力就大大降低了。到那时，这更像是一种商业模式验证：你能否创造出足够盈利的产品线，来负担以这种方式开发软件所产生的巨大开销？

当任何竞争对手都可能通过几小时的智能体编码工作就克隆出你的最新功能时，构建可持续的软件业务也会呈现出截然不同的面貌。

我希望这些模式能够以低得多的成本投入实践。我个人发现每月200美元的Claude Max套餐为我提供了充足的空间来试验不同的智能体模式，当然我也不是24小时不间断地运行着一群质量保证测试员！

我认为即使对于那些不会在代币成本上花费数千美元的团队和个人来说，StrongDM也有很多值得学习的地方。我特别关注的问题是：如何让智能体证明它们编写的代码有效，而无需逐行审查它们生成的每一行代码。

标签：
人工智能，
生成式人工智能，
大语言模型，
人工智能辅助编程，
编码智能体，
并行智能体&lt;/p&gt;
&lt;p&gt;If these patterns really do add $20,000/month per engineer to your budget they're far less interesting to me. At that point this becomes more of a business model exercise: can you create a profitable enough line of products that you can afford the enormous overhead of developing software in this way?&lt;/p&gt;
&lt;p&gt;Building sustainable software businesses also looks very different when any competitor can potentially clone your newest features with a few hours of coding agent work.&lt;/p&gt;
&lt;p&gt;I hope these patterns can be put into play with a much lower spend. I've personally found the $200/month Claude Max plan gives me plenty of space to experiment with different agent patterns, but I'm also not running a swarm of QA testers 24/7!&lt;/p&gt;
&lt;p&gt;I think there's a lot to learn from StrongDM even for teams and individuals who aren't going to burn thousands of dollars on token costs. I'm particularly invested in the question of what it takes to have agents prove that their code works without needing to review every line of code they produce.&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/parallel-agents"&gt;parallel-agents&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sat, 07 Feb 2026 15:40:48 +0000</pubDate></item><item><title>引用汤姆·戴尔的话</title><link>https://simonwillison.net/2026/Feb/6/tom-dale/#atom-everything</link><description>&lt;blockquote cite="https://twitter.com/tomdale/status/2019828626972131441"&gt;&lt;p&gt;不知为何这周成了临界点，与我交谈过的几乎每位软件工程师都正经历某种程度的心理健康危机。

[...] 许多人以为我指的是失业焦虑，但这只是表象之一。我目睹着软件从稀缺转向过剩所引发的近乎狂躁的状态。围绕智能体使用的强迫性行为。面对变革时间压缩产生的解离性惊愕。这不一定是恐惧，而是在历史拐点中生存所承受的认知超载。

——
汤姆·戴尔

标签：
人工智能伦理，
职业生涯，
编程智能体，
生成式人工智能，
人工智能，
大语言模型&lt;/p&gt;
&lt;p&gt;[...] Many people assuming I meant job loss anxiety but that's just one presentation. I'm seeing near-manic episodes triggered by watching software shift from scarce to abundant. Compulsive behaviors around agent usage. Dissociative awe at the temporal compression of change. It's not fear necessarily just the cognitive overload from living in an inflection point.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;— &lt;a href="https://twitter.com/tomdale/status/2019828626972131441"&gt;Tom Dale&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/careers"&gt;careers&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;&lt;/p&gt;</description><pubDate>Fri, 06 Feb 2026 23:41:31 +0000</pubDate></item><item><title>在WebAssembly中运行Pydantic的Monty Rust沙盒化Python子集</title><link>https://simonwillison.net/2026/Feb/6/pydantic-monty/#atom-everything</link><description>&lt;p&gt;这标题真是术语满满！现在大家都在为运行不可信代码构建沙箱，而Pydantic的最新尝试——Monty——在Rust中实现了一种自定义类Python语言（Python子集），并同时提供Rust库和Python包两种使用方式。我成功将其运行在WebAssembly环境中，实现了“沙箱中的沙箱”。

以下是他们对Monty的描述：
Monty避免了使用完整容器沙箱运行LLM生成代码所带来的成本、延迟、复杂性和各种繁琐操作。相反，它让你能安全运行嵌入智能体中的LLM编写的Python代码，启动时间仅需个位数微秒而非数百毫秒。

Monty的功能：
- 运行合理的Python代码子集——足以让智能体表达其意图
- 完全隔离宿主环境：文件系统、环境变量和网络访问均通过开发者可控的外部函数调用实现
- 调用宿主函数——仅限你授权访问的功能

快速体验方式是通过uv工具：
然后在Python交互式环境中粘贴以下代码（需启用顶层await）：
```python
import pydantic_monty
code = pydantic_monty.Monty('print("hello " + str(4 * 5))')
await pydantic_monty.run_monty_async(code)
```

Monty目前仅支持极小的Python子集——甚至还不支持类声明！但针对其目标使用场景，这实际上不成问题。为LLM提供此类工具的妙处在于，它们非常擅长根据错误信息进行迭代调整。编码智能体可以运行Python代码，收到不支持类的错误提示后，就能尝试其他实现方式。

我想在浏览器中尝试这个功能，于是在Claude Code网页版中创建了代码研究任务，以下列指令启动：
克隆 https://github.com/pydantic/monty&lt;a href="https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-we-re-finally-going-to-solve-sandboxing"&gt;building sandboxes&lt;/a&gt; for running untrusted code right now, and Pydantic's latest attempt, &lt;a href="https://github.com/pydantic/monty"&gt;Monty&lt;/a&gt;, provides a custom Python-like language (a subset of Python) in Rust and makes it available as both a Rust library and a Python package. I got it working in WebAssembly, providing a sandbox-in-a-sandbox.&lt;/p&gt;
&lt;p&gt;Here's &lt;a href="https://github.com/pydantic/monty"&gt;how they describe Monty&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Monty avoids the cost, latency, complexity and general faff of using full container based sandbox for running LLM generated code.&lt;/p&gt;
&lt;p&gt;Instead, it let's you safely run Python code written by an LLM embedded in your agent, with startup times measured in single digit microseconds not hundreds of milliseconds.&lt;/p&gt;
&lt;p&gt;What Monty &lt;strong&gt;can&lt;/strong&gt; do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run a reasonable subset of Python code - enough for your agent to express what it wants to do&lt;/li&gt;
&lt;li&gt;Completely block access to the host environment: filesystem, env variables and network access are all implemented via external function calls the developer can control&lt;/li&gt;
&lt;li&gt;Call functions on the host - only functions you give it access to [...]&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;A quick way to try it out is via &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uv run --with pydantic-monty python -m asyncio
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then paste this into the Python interactive prompt - the &lt;code&gt;-m asyncio&lt;/code&gt; enables top-level await:&lt;/p&gt;
&lt;pre&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;pydantic_monty&lt;/span&gt;
&lt;span&gt;code&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;pydantic_monty&lt;/span&gt;.&lt;span&gt;Monty&lt;/span&gt;(&lt;span&gt;'print("hello " + str(4 * 5))'&lt;/span&gt;)
&lt;span&gt;await&lt;/span&gt; &lt;span&gt;pydantic_monty&lt;/span&gt;.&lt;span&gt;run_monty_async&lt;/span&gt;(&lt;span&gt;code&lt;/span&gt;)&lt;/pre&gt;
&lt;p&gt;Monty supports a &lt;em&gt;very&lt;/em&gt; small subset of Python - it doesn't even support class declarations yet!&lt;/p&gt;
&lt;p&gt;But, given its target use-case, that's not actually a problem.&lt;/p&gt;
&lt;p&gt;The neat thing about providing tools like this for LLMs is that they're really good at iterating against error messages. A coding agent can run some Python code, get an error message telling it that classes aren't supported and then try again with a different approach.&lt;/p&gt;
&lt;p&gt;I wanted to try this in a browser, so I fired up &lt;a href="https://simonwillison.net/2025/Nov/6/async-code-research/"&gt;a code research task&lt;/a&gt; in Claude Code for web and kicked it off with the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Clone &lt;a href="https://github.com/pydantic/monty"&gt;https://github.com/pydantic/monty&lt;/a&gt;将代码编译到 /tmp 目录，并研究如何将其打包成可在 Pyodide 中加载的 Python WebAssembly wheel 文件。该 wheel 文件需与构建脚本、以及通过 pytest playwright 测试的脚本一同提交至代码仓库——这些测试脚本会从 CDN 加载 Pyodide，并通过本地 "python -m http.server" 加载 wheel 文件，以验证其正常运行。

随后需要额外构建一个独立于 Pyodide 的 WASM 文件，使其也能在浏览器中直接运行。同时需配套编写 playwright 测试来验证其功能，并创建两个 HTML 演示文件：demo.html 与 pyodide-demo.html。这两个文件应参考 https://tools.simonwillison.net/micropython 的实现方式（可通过 curl 下载该代码进行研究），其中一个直接加载 WASM 构建文件，另一个则加载 Pyodide 并调用 WASM wheel。由于这些文件将通过 GitHub Pages 提供服务，且 HTML 文件与 wheel/WASM 文件位于同一目录，因此可以使用相对路径进行加载。

以下是完整的开发记录与最终研究报告。

目前我已将 Monty Rust 代码编译成两种形态的 WebAssembly：一种是可直接通过 JavaScript 加载调用的捆绑包，另一种是可在 Pyodide 中加载的 wheel 文件——后者使得在浏览器中的 WebAssembly 环境里，能通过 Pyodide 的 Python 接口进行调用。

这两个演示已部署在 GitHub Pages 上：
- Monty WASM 演示：通过 JavaScript 直接加载 Rust WASM 模块的交互界面。
- Monty Pyodide 演示：提供相同交互界面，但改为加载 Pyodide 后安装 Monty WASM wheel 的实现方式。

作为沙盒技术的鉴赏者——选择越多越好！——Pydantic 推出的这个新方案完全符合我的期待。它体积小巧、运行高效、具备良好的跨平台性（得益于 Rust 与 WebAssembly），并能严格限制内存使用、CPU 时间以及磁盘网络访问权限。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then a little later:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I want an additional WASM file that works independently of Pyodide, which is also usable in a web browser - build that too along with playwright tests that show it working. Also build two HTML files - one called demo.html and one called pyodide-demo.html - these should work similar to &lt;a href="https://tools.simonwillison.net/micropython"&gt;https://tools.simonwillison.net/micropython&lt;/a&gt; (download that code with curl to inspect it) - one should load the WASM build, the other should load Pyodide and have it use the WASM wheel. These will be served by GitHub Pages so they can load the WASM and wheel from a relative path since the .html files will be served from the same folder as the wheel and WASM file&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here's &lt;a href="https://gisthost.github.io/?22d88e6367d7e002c4fb383c213c2df2/page-001.html"&gt;the transcript&lt;/a&gt;, and the &lt;a href="https://github.com/simonw/research/tree/main/monty-wasm-pyodide"&gt;final research report&lt;/a&gt; it produced.&lt;/p&gt;
&lt;p&gt;I now have the Monty Rust code compiled to WebAssembly in two different shapes - as a &lt;code&gt;.wasm&lt;/code&gt; bundle you can load and call from JavaScript, and as a &lt;code&gt;monty-wasm-pyodide/pydantic_monty-0.0.3-cp313-cp313-emscripten_4_0_9_wasm32.whl&lt;/code&gt; wheel file which can be loaded into &lt;a href="https://pyodide.org/"&gt;Pyodide&lt;/a&gt; and then called from Python in Pyodide in WebAssembly in a browser.&lt;/p&gt;
&lt;p&gt;Here are those two demos, hosted on GitHub Pages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://simonw.github.io/research/monty-wasm-pyodide/demo.html"&gt;Monty WASM demo&lt;/a&gt; - a UI over JavaScript that loads the Rust WASM module directly.&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://simonw.github.io/research/monty-wasm-pyodide/pyodide-demo.html"&gt;Monty Pyodide demo&lt;/a&gt; - this one provides an identical interface but here the code is &lt;a href="https://github.com/simonw/research/blob/3add1ffec70b530711fa237d91f546da5bcf1f1c/monty-wasm-pyodide/pyodide-demo.html#L257-L280"&gt;loading Pyodide and then installing the Monty WASM wheel&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Screenshot of a web app titled &amp;quot;Monty via Pyodide&amp;quot; with description &amp;quot;Run Monty (a sandboxed Python interpreter by Pydantic) inside Pyodide (CPython compiled to WebAssembly). This loads the pydantic-monty wheel and uses its full Python API. Code is saved in the URL for sharing.&amp;quot; A green banner reads &amp;quot;Code executed successfully!&amp;quot; Below are example buttons labeled &amp;quot;Basic&amp;quot;, &amp;quot;Inputs&amp;quot;, &amp;quot;Reuse&amp;quot;, &amp;quot;Error Handling&amp;quot;, &amp;quot;Fibonacci&amp;quot;, and &amp;quot;Classes&amp;quot;. A code editor labeled &amp;quot;Python Code (runs inside Monty sandbox via Pyodide):&amp;quot; contains: &amp;quot;import pydantic_monty\n\n# Create interpreter with input variables\nm = pydantic_monty.Monty('x + y', inputs=['x', 'y'])\n\n# Run with different inputs\nresult1 = m.run(inputs={&amp;quot;x&amp;quot;: 10, &amp;quot;y&amp;quot;: 20})\nprint(f&amp;quot;10 + 20 = {result1}&amp;quot;)\n\nresult2 = m.run(inputs={&amp;quot;x&amp;quot;: 100, &amp;quot;y&amp;quot;: 200})&amp;quot; with &amp;quot;Run Code&amp;quot; and &amp;quot;Clear&amp;quot; buttons. The Output section shows &amp;quot;10 + 20 = 30&amp;quot; and &amp;quot;100 + 200 = 300&amp;quot; with a &amp;quot;Copy&amp;quot; button. Footer reads &amp;quot;Executed in 4.0ms&amp;quot;." src="https://static.simonwillison.net/static/2026/monty-pyodide.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;As a connoisseur of sandboxes - the more options the better! - this new entry from Pydantic ticks a lot of my boxes. It's small, fast, widely available (thanks to Rust and WebAssembly) and provides strict limits on memory usage, CPU time and access to disk and network.&lt;/p&gt;
&lt;p&gt;这也是一个绝佳的契机，可以再做一个演示，展示如今将C或Rust这类编译代码转换成WebAssembly是多么容易，它既能在浏览器中运行，也能在Pyodide环境下执行。&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/javascript"&gt;javascript&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/sandboxing"&gt;sandboxing&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/rust"&gt;rust&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/webassembly"&gt;webassembly&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pyodide"&gt;pyodide&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pydantic"&gt;pydantic&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/claude-code"&gt;claude-code&lt;/a&gt;&lt;/p&gt;</description><pubDate>Fri, 06 Feb 2026 22:31:31 +0000</pubDate></item><item><title>Heroku 最新动态</title><link>https://simonwillison.net/2026/Feb/6/an-update-on-heroku/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.heroku.com/blog/an-update-on-heroku/"&gt;Heroku近况更新&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;Heroku官方博客上出现这个不祥的标题，是的，这是个坏消息。
&lt;blockquote&gt;
&lt;p&gt;从今天起，Heroku将转向以稳定性、安全性、可靠性和技术支持为核心的持续性工程模式。该平台仍将保持生产就绪状态并获得积极支持，但工作重心将转向维持服务质量与卓越运营，而非开发新功能。我们理解此类调整可能引发疑问，因此希望向客户明确说明这意味着什么。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据上下文推测，"持续性工程模式"（这绝非行业通用术语）大概意味着他们只维持基础运行。&lt;/p&gt;
&lt;p&gt;这份企业通告实在令人沮丧。"我们希望向客户明确说明这意味着什么"——然后紧接着&lt;em&gt;并未阐明&lt;/em&gt;这对客户意味着什么。&lt;/p&gt;
&lt;p&gt;他们为何如此决策？以下是官方解释：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们将把产品与工程资源集中投入能创造最大长期客户价值的领域，包括帮助企业在安全可信的环境中构建部署企业级人工智能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我的博客是唯一还运行在Heroku上的项目。看来最好在Salesforce彻底失去兴趣前迁移出去（或许该选Fly）。&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/salesforce"&gt;salesforce&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/heroku"&gt;heroku&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/fly"&gt;fly&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Fri, 06 Feb 2026 18:44:21 +0000</pubDate></item><item><title>引用卡雷尔·杜斯特林克的话</title><link>https://simonwillison.net/2026/Feb/6/karel-doosterlinck/#atom-everything</link><description>&lt;blockquote cite="https://twitter.com/kareldoostrlnck/status/2019477361557926281"&gt;&lt;p&gt;当我想在不熟悉的代码库中快速实现一次性实验时，我会让Codex进行全面的尽职调查。Codex会探索相关的Slack频道，阅读相关讨论，从这些讨论中获取实验分支，并为我的实验精选有用的更改。所有这些都会被总结成一套详尽的笔记，并附有每条信息来源的链接。利用这些笔记，Codex会搭建实验框架，并做出许多超参数决策，这些决策如果没有更多努力，我是不可能做出的。

---

Karel D'Oosterlinck

，我花了10,000美元用Codex在OpenAI自动化我的研究

标签：
codex-cli
,
coding-agents
,
ai-assisted-programming
,
generative-ai
,
openai
,
ai
,
llms&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;— &lt;a href="https://twitter.com/kareldoostrlnck/status/2019477361557926281"&gt;Karel D'Oosterlinck&lt;/a&gt;, I spent $10,000 to automate my research at OpenAI with Codex&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/codex-cli"&gt;codex-cli&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/coding-agents"&gt;coding-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;&lt;/p&gt;</description><pubDate>Fri, 06 Feb 2026 00:42:22 +0000</pubDate></item><item><title>米切尔·哈希莫夫：我的人工智能应用之旅</title><link>https://simonwillison.net/2026/Feb/5/ai-adoption-journey/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://mitchellh.com/writing/my-ai-adoption-journey"&gt;Mitchell Hashimoto：我的AI应用之旅&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;文中包含一些非常规但极其实用的技巧，能帮助你将编程助手真正融入工作流并切实提升效率。我特别欣赏以下几点：
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-2-reproduce-your-own-work"&gt;复现自己的工作成果&lt;/a&gt;- 在学习使用编程助手时，Mitchell曾经历这样一个阶段：先手动完成任务，再刻意训练助手复现相同解决方案：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我确实把每项工作都做了两遍。先手动完成，然后引导助手在无法参考我手动方案的前提下，产出质量与功能完全一致的结果。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-3-end-of-day-agents"&gt;每日收工助手&lt;/a&gt;- 在精力耗尽时让助手接手工作：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为了提升效率，我开始尝试新模式：&lt;strong&gt;每天预留最后30分钟启动一个或多个助手。&lt;/strong&gt;我的设想是：&lt;em&gt;或许&lt;/em&gt;当我自己无法继续工作时，助手仍能取得&lt;em&gt;实质性进展&lt;/em&gt;从而提升整体效率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-4-outsource-the-slam-dunks"&gt;外包确定性任务&lt;/a&gt;- 当你确认助手能胜任某项任务时，就交由它处理，自己则专注于更有挑战性的工作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;small&gt;&lt;/small&gt;来源：&lt;a href="https://news.ycombinator.com/item?id=46903558"&gt;Hacker News&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/ai"&gt;人工智能&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/generative-ai"&gt;生成式AI&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/llms"&gt;大语言模型&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;AI辅助编程&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/mitchell-hashimoto"&gt;mitchell-hashimoto&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/coding-agents"&gt;编程助手&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 05 Feb 2026 23:39:07 +0000</pubDate></item><item><title>作品4.6与法典5.3</title><link>https://simonwillison.net/2026/Feb/5/two-new-models/#atom-everything</link><description>&lt;p&gt;今天两大新模型相继发布，间隔仅约15分钟。

Anthropic推出了Opus 4.6版本，其宣传图如下：

OpenAI发布了GPT-5.3-Codex，不过目前仅通过其Codex应用程序提供，尚未开放API接口。其宣传图如下：

我提前体验了这两款模型，但说实话很难找到独特的报道角度——它们表现都非常出色，可之前的Codex 5.2和Opus 4.5同样优秀。我一直在寻找前代模型无法处理而新版能轻松胜任的任务，但至今没有明显发现。

目前关于新模型能力最令人信服的案例，来自Anthropic的尼古拉斯·卡里尼对Opus 4.6的介绍，以及他演示的"用并行Claude团队构建C编译器"项目——这相当于Anthropic版的Cursor FastRender项目。

标签：llm-release、anthropic、generative-ai、openai、pelican-riding-a-bicycle、ai、llms、parallel-agents、c、nicholas-carlini&lt;/p&gt;
&lt;p&gt;Anthropic &lt;a href="https://www.anthropic.com/news/claude-opus-4-6"&gt;released Opus 4.6&lt;/a&gt;. Here's &lt;a href="https://gist.github.com/simonw/a6806ce41b4c721e240a4548ecdbe216"&gt;its pelican&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Slightly wonky bicycle frame but an excellent pelican, very clear beak and pouch, nice feathers." src="https://static.simonwillison.net/static/2026/opus-4.6-pelican.png"/&gt;&lt;/p&gt;
&lt;p&gt;OpenAI &lt;a href="https://openai.com/index/introducing-gpt-5-3-codex/"&gt;release GPT-5.3-Codex&lt;/a&gt;, albeit only via their Codex app, not yet in their API. Here's &lt;a href="https://gist.github.com/simonw/bfc4a83f588ac762c773679c0d1e034b"&gt;its pelican&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Not nearly as good - the bicycle is a bit mangled, the pelican not nearly as well rendered - it's more of a line drawing." src="https://static.simonwillison.net/static/2026/codex-5.3-pelican.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've had a bit of preview access to both of these models and to be honest I'm finding it hard to find a good angle to write about them - they're both &lt;em&gt;really good&lt;/em&gt;, but so were their predecessors Codex 5.2 and Opus 4.5. I've been having trouble finding tasks that those previous models couldn't handle but the new ones are able to ace.&lt;/p&gt;
&lt;p&gt;The most convincing story about capabilities of the new model so far is Nicholas Carlini from Anthropic talking about Opus 4.6 and &lt;a href="https://www.anthropic.com/engineering/building-c-compiler"&gt;Building a C compiler with a team of parallel Claudes&lt;/a&gt; - Anthropic's version of Cursor's &lt;a href="https://simonwillison.net/2026/Jan/23/fastrender/"&gt;FastRender project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/llm-release"&gt;llm-release&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/anthropic"&gt;anthropic&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/openai"&gt;openai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pelican-riding-a-bicycle"&gt;pelican-riding-a-bicycle&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/parallel-agents"&gt;parallel-agents&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/c"&gt;c&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/nicholas-carlini"&gt;nicholas-carlini&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 05 Feb 2026 20:29:20 +0000</pubDate></item><item><title>聚焦《世界概况》，深情告别</title><link>https://simonwillison.net/2026/Feb/5/the-world-factbook/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.cia.gov/stories/story/spotlighting-the-world-factbook-as-we-bid-a-fond-farewell/"&gt;聚焦《世界概况》的告别时刻&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;今日从中央情报局传来令人扼腕的消息：
&lt;blockquote&gt;
&lt;p&gt;中情局历史最悠久、最具辨识度的情报出版物《世界概况》已悄然落幕。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方未透露任何&lt;em&gt;终止原因&lt;/em&gt;——这份自1971年起成为该机构最实用的公共窗口、1997年以来作为互联网公共基石的重要出版物，其维护更新戛然而止。&lt;/p&gt;
&lt;p&gt;更令人费解的是，他们不仅彻底关闭网站（包括所有历史版本存档），还将每个页面设置为跳转至停更公告的302重定向，此举堪称数字文化遗产的破坏行为。&lt;/p&gt;
&lt;p&gt;鉴于《世界概况》始终属于公共领域作品，本可继续提供存档版本——只需在页面顶端标注"停止维护"的提示，远比彻底抹去这些珍贵资料更为妥当。&lt;/p&gt;
&lt;p&gt;截至2020年，中情局仍每年发布完整的网站压缩包存档。这些资料（连同《世界概况》其他内容）&lt;a href="https://web.archive.org/web/20260203124934/https://www.cia.gov/the-world-factbook/about/archives/"&gt;现存于互联网档案馆&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我已将2020年度的384MB&lt;code&gt;.zip&lt;/code&gt;压缩包下载解压至新建的GitHub仓库&lt;a href="https://github.com/simonw/cia-world-factbook-2020/"&gt;simonw/cia-world-factbook-2020&lt;/a&gt;，并启用GitHub Pages功能，您可通过&lt;a href="https://simonw.github.io/cia-world-factbook-2020"&gt;simonw.github.io/cia-world-factbook-2020/&lt;/a&gt;浏览这份存档。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot of the CIA World Factbook website homepage. Header reads &amp;quot;THE WORLD FACTBOOK&amp;quot; with a dropdown labeled &amp;quot;Please select a country to view.&amp;quot; Navigation tabs: ABOUT, REFERENCES, APPENDICES, FAQs. Section heading &amp;quot;WELCOME TO THE WORLD FACTBOOK&amp;quot; followed by descriptive text: &amp;quot;The World Factbook provides information on the history, people and society, government, economy, energy, geography, communications, transportation, military, and transnational issues for 267 world entities. The Reference tab includes: a variety of world, regional, country, ocean, and time zone maps; Flags of the World; and a Country Comparison function that ranks the country information and data in more than 75 Factbook fields.&amp;quot; A satellite image of Earth is displayed on the right. Below it: &amp;quot;WHAT'S NEW :: Today is: Wednesday, February 4.&amp;quot; Left sidebar links with icons: WORLD TRAVEL FACTS, ONE-PAGE COUNTRY SUMMARIES, REGIONAL AND WORLD MAPS, FLAGS OF THE WORLD, GUIDE TO COUNTRY COMPARISONS. Right side shows news updates dated December 17, 2020 about Electricity access and new Economy fields, and December 10, 2020 about Nepal and China agreeing on the height of Mount Everest at 8,848.86 meters. A &amp;quot;VIEW ALL UPDATES&amp;quot; button appears at the bottom." src="https://static.simonwillison.net/static/2025/factbook-2020.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;从2020年12月10日的&lt;a href="https://simonw.github.io/cia-world-factbook-2020/docs/whatsnew.html"&gt;更新日志&lt;/a&gt;中，可窥见《世界概况》独特的编辑风格：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;尼泊尔与中国官员本周宣布就珠穆朗玛峰海拔达成共识，终结了多年的测量争议。这座位于尼中边境的山峰在2015年地震后高度略有变化，新确认的8848.86米海拔较原有数据高出近一米。&lt;em&gt;《世界概况》&lt;/em&gt;将新数据取整为8849米，并已同步更新至&lt;em&gt;全书数据库&lt;/em&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;small&gt;&lt;/small&gt;消息来源：&lt;a href="https://news.ycombinator.com/item?id=46891794"&gt;黑客新闻&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/cia"&gt;中情局&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/github"&gt;GitHub&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/internet-archive"&gt;互联网档案馆&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 05 Feb 2026 00:23:38 +0000</pubDate></item><item><title>Voxtral以声速转录。</title><link>https://simonwillison.net/2026/Feb/4/voxtral-2/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://mistral.ai/news/voxtral-transcribe-2"&gt;Voxtral以声速转录&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;Mistral刚刚发布了Voxtral Transcribe 2系列——包含两个新模型，其中一个是开源权重模型，用于将音频转录为文本。这是他们类似Whisper模型家族的最新成员，也是2025年7月发布的初代Voxtral的续作。&lt;a href="https://simonwillison.net/2025/Jul/16/voxtral/"&gt;Voxtral Realtime（官方名称）是开源权重（Apache-2.0许可）模型，可通过Hugging Face下载8.87GB文件。&lt;/a&gt;您可以通过这个实时演示体验——不要被“未找到麦克风”的提示吓退，点击“录制”按钮后浏览器会请求权限并启动演示。该演示令我印象深刻：我快速说话并使用了Django、WebAssembly等专业术语，它几乎在我发出每个音节的同时就准确转录了文本。
&lt;p&gt;闭源权重模型名为voxtral-mini-latest，可通过Mistral API调用，请求示例如下：&lt;code&gt;Voxtral-Mini-4B-Realtime-2602&lt;/code&gt;API端点：https://api.mistral.ai/v1/audio/transcriptions&lt;a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602"&gt;请求头：Authorization: Bearer $MISTRAL_API_KEY&lt;/a&gt;模型参数："voxtral-mini-latest"&lt;/p&gt;
&lt;p&gt;文件参数："Pelican talk at the library.m4a"&lt;a href="https://huggingface.co/spaces/mistralai/Voxtral-Mini-Realtime"&gt;响应格式："Datasette"&lt;/a&gt;分段模式："segment"&lt;/p&gt;
&lt;p&gt;该服务定价为每分钟0.003美元（即每小时0.18美元）。&lt;code&gt;voxtral-mini-latest&lt;/code&gt;Mistral API控制台现已推出语音转文本测试平台，可流畅体验新模型。您可以通过简洁的界面上传音频文件，即时获得带说话人分离的转录结果，并支持以文本、SRT或JSON格式下载。&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;curl -X POST &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;消息来源：Hacker News&lt;/span&gt;标签：人工智能, 生成式AI, 大语言模型, Hugging Face, Mistral, 语音转文本&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  -H &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Authorization: Bearer &lt;span class="pl-smi"&gt;$MISTRAL_API_KEY&lt;/span&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  -F model=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;voxtral-mini-latest&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  -F file=@&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Pelican talk at the library.m4a&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  -F diarize=true \
  -F context_bias=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Datasette&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; \
  -F timestamp_granularities=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;segment&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's priced at $0.003/minute, which is $0.18/hour.&lt;/p&gt;
&lt;p&gt;The Mistral API console now has a &lt;a href="https://console.mistral.ai/build/audio/speech-to-text"&gt;speech-to-text playground&lt;/a&gt; for exercising the new model and it is &lt;em&gt;excellent&lt;/em&gt;. You can upload an audio file and promptly get a diarized transcript in a pleasant interface, with options to download the result in text, SRT or JSON format.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot of a speech-to-text transcription interface for a file named &amp;quot;Pelican talk at the library.m4a&amp;quot;. The toolbar shows &amp;quot;Speech to text&amp;quot; with Code, Transcribe, and Download buttons. The transcript shows timestamped segments from 5:53 to 6:53 with a speaker icon, reading: &amp;quot;5:53 – 6:01 So pelicans love to, they're very good at getting the most they can out of the topography when they're flying. 6:01 – 6:06 And our winds come in from the northwest and they hit those bluffs and they're deflected up. 6:07 – 6:18 And they will sit right, they'll fly north into a wind like five feet off those bluffs, but just five or ten feet off the surface because the winds dissipate. 6:19 – 6:22 And they will surf that bluff all the way north. 6:23 – 6:30 So you'll see a wind from the north at 15 miles an hour, and the pelicans are flying north into that wind and not flapping their wings. 6:31 – 6:33 And it's one of the coolest things. 6:33 – 6:35 You can only find it on San Francisco Coast. 6:36 – 6:39 Where right where the bluffs are steep. 6:41 – 6:43 Pacifica, you can find them there. 6:43 – 6:51 They like their, what we call pier bums, which are typically pelicans that have, are in some sort of trouble. 6:51 – 6:53 They're unable to catch food.&amp;quot; The segment at 6:41–6:43 is highlighted in yellow. An audio waveform is shown at the bottom with a playhead near 6:40. Stats in the lower right show 53.90s, 7946.00s, and #45833." src="https://static.simonwillison.net/static/2025/mistral-transcript-ui.jpg"/&gt;
&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href="https://news.ycombinator.com/item?id=46886735"&gt;Hacker News&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/hugging-face"&gt;hugging-face&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/mistral"&gt;mistral&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/speech-to-text"&gt;speech-to-text&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Wed, 04 Feb 2026 22:42:34 +0000</pubDate></item><item><title>通过go-to-wheel工具，将Go语言编译的二进制文件（如sqlite-scanner）打包成Python wheel包，并通过PyPI进行分发。</title><link>https://simonwillison.net/2026/Feb/4/distributing-go-binaries/#atom-everything</link><description>&lt;p&gt;最近我一直在探索用Go语言构建小巧、快速且自包含的二进制应用程序。我很喜欢它通常只有一种明确的实现方式，生成的代码简洁易读——而且大语言模型也很擅长编写这类代码。唯一的难点在于分发，但事实证明，将Go二进制文件发布到PyPI意味着任何Go二进制程序都可以通过一行命令轻松调用。

sqlite-scanner是我新开发的Go命令行工具，用于扫描文件系统中的SQLite数据库文件。

它的工作原理是检查文件的前16个字节是否完全匹配SQLite的魔数序列。它可以递归搜索一个或多个文件夹，通过启动并发goroutine来加速扫描过程。工具会以纯文本、JSON或换行分隔的JSON格式实时输出扫描结果，并可选显示文件大小。

要试用它，你可以从GitHub releases下载发行版——然后经历macOS的繁琐步骤来执行这个“不安全”的二进制文件。或者你也可以克隆代码仓库并用Go编译。又或者……你可以直接这样运行二进制文件：

默认情况下，这将在当前目录中搜索SQLite数据库。你也可以传入一个或多个目录作为参数：

添加参数可获得JSON输出，添加可包含文件大小，或使用换行分隔的JSON格式。以下是一个演示：

如果你尚未使用uv工具，也可以通过pip安装sqlite-scanner，然后运行。

若要通过uv获取永久副本，请使用。

Python包的工作原理

这样做的价值在于，pip、uv和PyPI将协同工作，为你的操作系统和架构识别正确的编译二进制文件。

这主要通过文件名实现。如果你访问sqlite-scanner的PyPI下载页面，会看到以下文件：

当我在苹果芯片的Mac笔记本上运行或时，Python的打包机制会确保我获取到对应的变体。

以下是wheel文件（扩展名为.zip）中的内容：

除了二进制文件外，最重要的文件是，其中包含以下代码：

def get_binary_path():
    """返回捆绑二进制文件的路径。"""
    binary = os.path.join(os.path.dirname(__file__), "bin")&lt;code&gt;uvx package-name&lt;/code&gt; call away.&lt;/p&gt;
&lt;h4 id="sqlite-scanner"&gt;sqlite-scanner&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/simonw/sqlite-scanner"&gt;sqlite-scanner&lt;/a&gt; is my new Go CLI tool for scanning a filesystem for SQLite database files.&lt;/p&gt;
&lt;p&gt;It works by checking if the first 16 bytes of the file exactly match the SQLite magic number sequence &lt;code&gt;SQLite format 3\x00&lt;/code&gt;. It can search one or more folders recursively, spinning up concurrent goroutines to accelerate the scan. It streams out results as it finds them in plain text, JSON or newline-delimited JSON. It can optionally display the file sizes as well.&lt;/p&gt;
&lt;p&gt;To try it out you can download a release from the &lt;a href="https://github.com/simonw/sqlite-scanner/releases"&gt;GitHub releases&lt;/a&gt; - and then &lt;a href="https://support.apple.com/en-us/102445"&gt;jump through macOS hoops&lt;/a&gt; to execute an "unsafe" binary. Or you can clone the repo and compile it with Go. Or... you can run the binary like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uvx sqlite-scanner
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default this will search your current directory for SQLite databases. You can pass one or more directories as arguments:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uvx sqlite-scanner ~ /tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add &lt;code&gt;--json&lt;/code&gt; for JSON output, &lt;code&gt;--size&lt;/code&gt; to include file sizes or &lt;code&gt;--jsonl&lt;/code&gt; for newline-delimited JSON. Here's a demo:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uvx sqlite-scanner ~ --jsonl --size
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt="running that command produces a sequence of JSON objects, each with a path and a size key" src="https://static.simonwillison.net/static/2025/sqlite-scanner-demo.gif"/&gt;&lt;/p&gt;
&lt;p&gt;If you haven't been uv-pilled yet you can instead install &lt;code&gt;sqlite-scanner&lt;/code&gt; using &lt;code&gt;pip install sqlite-scanner&lt;/code&gt; and then run &lt;code&gt;sqlite-scanner&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To get a permanent copy with &lt;code&gt;uv&lt;/code&gt; use &lt;code&gt;uv tool install sqlite-scanner&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id="how-the-python-package-works"&gt;How the Python package works&lt;/h4&gt;
&lt;p&gt;The reason this is worth doing is that &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; and &lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt; will work together to identify the correct compiled binary for your operating system and architecture.&lt;/p&gt;
&lt;p&gt;This is driven by file names. If you visit &lt;a href="https://pypi.org/project/sqlite-scanner/#files"&gt;the PyPI downloads for sqlite-scanner&lt;/a&gt; you'll see the following files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-win_arm64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-win_amd64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-musllinux_1_2_x86_64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-musllinux_1_2_aarch64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-manylinux_2_17_x86_64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-manylinux_2_17_aarch64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-macosx_11_0_arm64.whl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sqlite_scanner-0.1.1-py3-none-macosx_10_9_x86_64.whl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When I run &lt;code&gt;pip install sqlite-scanner&lt;/code&gt; or &lt;code&gt;uvx sqlite-scanner&lt;/code&gt; on my Apple Silicon Mac laptop Python's packaging magic ensures I get that &lt;code&gt;macosx_11_0_arm64.whl&lt;/code&gt; variant.&lt;/p&gt;
&lt;p&gt;Here's &lt;a href="https://tools.simonwillison.net/zip-wheel-explorer?url=https%3A%2F%2Ffiles.pythonhosted.org%2Fpackages%2F88%2Fb1%2F17a716635d2733fec53ba0a8267f85bd6b6cf882c6b29301bc711fba212c%2Fsqlite_scanner-0.1.1-py3-none-macosx_11_0_arm64.whl#sqlite_scanner/__init__.py"&gt;what's in the wheel&lt;/a&gt;, which is a zip file with a &lt;code&gt;.whl&lt;/code&gt; extension.&lt;/p&gt;
&lt;p&gt;In addition to the &lt;code&gt;bin/sqlite-scanner&lt;/code&gt; the most important file is &lt;code&gt;sqlite_scanner/__init__.py&lt;/code&gt; which includes the following:&lt;/p&gt;
&lt;pre&gt;&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;get_binary_path&lt;/span&gt;():
    &lt;span class="pl-s"&gt;"""Return the path to the bundled binary."""&lt;/span&gt;
    &lt;span class="pl-s1"&gt;binary&lt;/span&gt; &lt;span class="pl-c1"&gt;=&lt;/span&gt; &lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;path&lt;/span&gt;.&lt;span class="pl-c1"&gt;join&lt;/span&gt;(&lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;path&lt;/span&gt;.&lt;span class="pl-c1"&gt;dirname&lt;/span&gt;(&lt;span class="pl-s1"&gt;__file__&lt;/span&gt;), &lt;span class="pl-s"&gt;"bin"&lt;/span&gt;, &lt;span class="pl-s"&gt;"sqlite-scanner"
# 确保Unix系统上二进制文件可执行
if sys.platform != "win32":
    current_mode = os.stat(binary).st_mode
    if not current_mode &amp;amp; stat.S_IXUSR:
        os.chmod(binary, current_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)
    return binary

def main():
    """执行捆绑的二进制文件。"""
    binary = get_binary_path()
    if sys.platform == "win32":
        # Windows系统使用subprocess正确处理信号
        sys.exit(subprocess.call([binary] + sys.argv[1:]))
    else:
        # Unix系统使用exec替换进程
        os.execvp(binary, [binary] + sys.argv[1:])

该方法（同样通过__main__.py调用）会在Python包被执行时定位并运行二进制文件，利用wheel中定义的入口点实现。这意味着我们可以将其作为依赖项使用。

虽然使用PyPI作为Go二进制文件的分发平台略显取巧，但已有诸多先例。我的理由是：这意味着我们现在可以将Go二进制文件作为其他Python包的依赖项——这确实非常实用！任何跨平台Go二进制文件的功能现在都能整合到Python包中。Python非常擅长运行子进程，这为我们打开了一扇新大门，可以将各种实用技巧融入Python工具。

为演示此功能，我构建了datasette-scan——这是一个新的Datasette插件，它依赖sqlite-scanner，并利用该Go二进制文件扫描文件夹中的SQLite数据库，将其附加到Datasette实例。以下是使用方法（借助pipx甚至无需预先安装任何软件）来探索Downloads文件夹中的所有SQLite数据库：

~
查看代码会发现，它在pyproject.toml中声明了对sqlite-scanner的依赖，并在其scan_directories()函数中通过subprocess.run()调用该二进制文件。

最近我还在探索将此模式应用于其他非Go二进制文件——这里有个最新脚本依赖static-ffmpeg来确保脚本运行时ffmpeg可用。

使用go-to-wheel从Go包构建Python wheel
在亲自尝试此模式几次后，我意识到需要工具来自动化此流程。我首先与Claude进行了构思探讨。&lt;/span&gt;)
 
    &lt;span class="pl-c"&gt;# Ensure binary is executable on Unix&lt;/span&gt;
    &lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-s1"&gt;sys&lt;/span&gt;.&lt;span class="pl-c1"&gt;platform&lt;/span&gt; &lt;span class="pl-c1"&gt;!=&lt;/span&gt; &lt;span class="pl-s"&gt;"win32"&lt;/span&gt;:
        &lt;span class="pl-s1"&gt;current_mode&lt;/span&gt; &lt;span class="pl-c1"&gt;=&lt;/span&gt; &lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;stat&lt;/span&gt;(&lt;span class="pl-s1"&gt;binary&lt;/span&gt;).&lt;span class="pl-c1"&gt;st_mode&lt;/span&gt;
        &lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-c1"&gt;not&lt;/span&gt; (&lt;span class="pl-s1"&gt;current_mode&lt;/span&gt; &lt;span class="pl-c1"&gt;&amp;amp;&lt;/span&gt; &lt;span class="pl-s1"&gt;stat&lt;/span&gt;.&lt;span class="pl-c1"&gt;S_IXUSR&lt;/span&gt;):
            &lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;chmod&lt;/span&gt;(&lt;span class="pl-s1"&gt;binary&lt;/span&gt;, &lt;span class="pl-s1"&gt;current_mode&lt;/span&gt; &lt;span class="pl-c1"&gt;|&lt;/span&gt; &lt;span class="pl-s1"&gt;stat&lt;/span&gt;.&lt;span class="pl-c1"&gt;S_IXUSR&lt;/span&gt; &lt;span class="pl-c1"&gt;|&lt;/span&gt; &lt;span class="pl-s1"&gt;stat&lt;/span&gt;.&lt;span class="pl-c1"&gt;S_IXGRP&lt;/span&gt; &lt;span class="pl-c1"&gt;|&lt;/span&gt; &lt;span class="pl-s1"&gt;stat&lt;/span&gt;.&lt;span class="pl-c1"&gt;S_IXOTH&lt;/span&gt;)
 
    &lt;span class="pl-k"&gt;return&lt;/span&gt; &lt;span class="pl-s1"&gt;binary&lt;/span&gt;
 
 
&lt;span class="pl-k"&gt;def&lt;/span&gt; &lt;span class="pl-en"&gt;main&lt;/span&gt;():
    &lt;span class="pl-s"&gt;"""Execute the bundled binary."""&lt;/span&gt;
    &lt;span class="pl-s1"&gt;binary&lt;/span&gt; &lt;span class="pl-c1"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;get_binary_path&lt;/span&gt;()
 
    &lt;span class="pl-k"&gt;if&lt;/span&gt; &lt;span class="pl-s1"&gt;sys&lt;/span&gt;.&lt;span class="pl-c1"&gt;platform&lt;/span&gt; &lt;span class="pl-c1"&gt;==&lt;/span&gt; &lt;span class="pl-s"&gt;"win32"&lt;/span&gt;:
        &lt;span class="pl-c"&gt;# On Windows, use subprocess to properly handle signals&lt;/span&gt;
        &lt;span class="pl-s1"&gt;sys&lt;/span&gt;.&lt;span class="pl-c1"&gt;exit&lt;/span&gt;(&lt;span class="pl-s1"&gt;subprocess&lt;/span&gt;.&lt;span class="pl-c1"&gt;call&lt;/span&gt;([&lt;span class="pl-s1"&gt;binary&lt;/span&gt;] &lt;span class="pl-c1"&gt;+&lt;/span&gt; &lt;span class="pl-s1"&gt;sys&lt;/span&gt;.&lt;span class="pl-c1"&gt;argv&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:]))
    &lt;span class="pl-k"&gt;else&lt;/span&gt;:
        &lt;span class="pl-c"&gt;# On Unix, exec replaces the process&lt;/span&gt;
        &lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;execvp&lt;/span&gt;(&lt;span class="pl-s1"&gt;binary&lt;/span&gt;, [&lt;span class="pl-s1"&gt;binary&lt;/span&gt;] &lt;span class="pl-c1"&gt;+&lt;/span&gt; &lt;span class="pl-s1"&gt;sys&lt;/span&gt;.&lt;span class="pl-c1"&gt;argv&lt;/span&gt;[&lt;span class="pl-c1"&gt;1&lt;/span&gt;:])&lt;/pre&gt;
&lt;p&gt;That &lt;code&gt;main()&lt;/code&gt; method - also called from &lt;code&gt;sqlite_scanner/__main__.py&lt;/code&gt; - locates the binary and executes it when the Python package itself is executed, using the &lt;code&gt;sqlite-scanner = sqlite_scanner:main&lt;/code&gt; entry point defined in the wheel.&lt;/p&gt;
&lt;h4 id="which-means-we-can-use-it-as-a-dependency"&gt;Which means we can use it as a dependency&lt;/h4&gt;
&lt;p&gt;Using PyPI as a distribution platform for Go binaries feels a tiny bit abusive, albeit &lt;a href="https://simonwillison.net/2022/May/23/bundling-binary-tools-in-python-wheels/"&gt;there is plenty of precedent&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll justify it by pointing out that this means &lt;strong&gt;we can use Go binaries as dependencies&lt;/strong&gt; for other Python packages now.&lt;/p&gt;
&lt;p&gt;That's genuinely useful! It means that any functionality which is available in a cross-platform Go binary can now be subsumed into a Python package. Python is really good at running subprocesses so this opens up a whole world of useful tricks that we can bake into our Python tools.&lt;/p&gt;
&lt;p&gt;To demonstrate this, I built &lt;a href="https://github.com/simonw/datasette-scan"&gt;datasette-scan&lt;/a&gt; - a new Datasette plugin which depends on &lt;code&gt;sqlite-scanner&lt;/code&gt; and then uses that Go binary to scan a folder for SQLite databases and attach them to a Datasette instance.&lt;/p&gt;
&lt;p&gt;Here's how to use that (without even installing anything first, thanks &lt;code&gt;uv&lt;/code&gt;) to explore any SQLite databases in your Downloads folder:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uv run --with datasette-scan datasette scan &lt;span class="pl-k"&gt;~&lt;/span&gt;/Downloads&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you peek at the code you'll see it &lt;a href="https://github.com/simonw/datasette-scan/blob/1a2b6d1e6b04c8cd05f5676ff7daa877efd99f08/pyproject.toml#L14"&gt;depends on sqlite-scanner&lt;/a&gt; in &lt;code&gt;pyproject.toml&lt;/code&gt; and calls it using &lt;code&gt;subprocess.run()&lt;/code&gt; against &lt;code&gt;sqlite_scanner.get_binary_path()&lt;/code&gt; in its own &lt;a href="https://github.com/simonw/datasette-scan/blob/1a2b6d1e6b04c8cd05f5676ff7daa877efd99f08/datasette_scan/__init__.py#L38-L58"&gt;scan_directories() function&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I've been exploring this pattern for other, non-Go binaries recently - here's &lt;a href="https://github.com/simonw/tools/blob/main/python/livestream-gif.py"&gt;a recent script&lt;/a&gt; that depends on &lt;a href="https://pypi.org/project/static-ffmpeg/"&gt;static-ffmpeg&lt;/a&gt; to ensure that &lt;code&gt;ffmpeg&lt;/code&gt; is available for the script to use.&lt;/p&gt;
&lt;h4 id="building-python-wheels-from-go-packages-with-go-to-wheel"&gt;Building Python wheels from Go packages with go-to-wheel&lt;/h4&gt;
&lt;p&gt;After trying this pattern myself a couple of times I realized it would be useful to have a tool to automate the process.&lt;/p&gt;
&lt;p&gt;I first &lt;a href="https://claude.ai/share/2d9ced56-b3e8-4651-83cc-860b9b419187"&gt;brainstormed with Claude&lt;/a&gt;为了确认没有现成的工具能完成这个任务，我进行了搜索。结果指向了&lt;a href="https://www.maturin.rs/bindings.html#bin"&gt;maturin bin&lt;/a&gt;这款工具，它帮助通过Python wheel分发Rust项目；还有&lt;a href="https://github.com/Bing-su/pip-binary-factory"&gt;pip-binary-factory&lt;/a&gt;它能打包各种其他项目，但并未找到能精准解决我问题的工具。&lt;/p&gt;
&lt;p&gt;于是，我&lt;a href="https://gisthost.github.io/?41f04e4eb823b1ceb888d9a28c2280dd/index.html"&gt;借助Claude Code在网页上构建了第一个版本&lt;/a&gt;，然后在我的笔记本电脑上，结合更多Claude Code和一点OpenAI Codex的帮助，对代码进行了本地优化，只为增添一些变化。&lt;/p&gt;
&lt;p&gt;完整的文档位于&lt;a href="https://github.com/simonw/go-to-wheel"&gt;simonw/go-to-wheel&lt;/a&gt;仓库中。我已将该工具发布到PyPI，现在你可以通过以下方式运行它：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvx go-to-wheel --help&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你在PyPI上&lt;code&gt;sqlite-scanner&lt;/code&gt;看到的&lt;a href="https://pypi.org/project/sqlite-scanner/"&gt;这个包&lt;/a&gt;是通过&lt;code&gt;go-to-wheel&lt;/code&gt;类似这样的方式构建的：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvx go-to-wheel &lt;span class="pl-k"&gt;~&lt;/span&gt;/dev/sqlite-scanner \
  --set-version-var main.version \
  --version 0.1.1 \
  --readme README.md \
  --author &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;Simon Willison&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt; \
  --url https://github.com/simonw/sqlite-scanner \
  --description &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;'&lt;/span&gt;扫描目录中的SQLite数据库&lt;span class="pl-pds"&gt;'&lt;/span&gt;&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这会在&lt;code&gt;dist/&lt;/code&gt;文件夹中创建一组wheel文件。我通过以下方式测试了其中一个：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uv run --with dist/sqlite_scanner-0.1.1-py3-none-macosx_11_0_arm64.whl \
  sqlite-scanner --version&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当它正确输出版本号时，我确信一切按计划进行，于是使用&lt;code&gt;twine upload&lt;/code&gt;将整套wheel文件推送到PyPI，操作如下：&lt;/p&gt;
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;uvx twine upload dist/&lt;span class="pl-k"&gt;*&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我只需粘贴之前保存的PyPI API令牌，就完成了所有步骤。&lt;/p&gt;
&lt;h4 id="i-expect-to-use-this-pattern-a-lot"&gt;我预计会频繁使用这种模式&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;sqlite-scanner&lt;/code&gt;这显然是为了验证更广泛模式的概念证明——Python完全有能力自行递归遍历目录结构，寻找以特定字节前缀开头的文件！&lt;/p&gt;
&lt;p&gt;话虽如此，我认为这种模式&lt;em&gt;有很多&lt;/em&gt;值得称道之处。Go是Python的绝佳补充——它速度快，编译为小巧独立的二进制文件，拥有出色的并发支持和丰富的库生态系统。&lt;/p&gt;
&lt;p&gt;Go与Python相似之处在于它拥有强大的标准库。Go尤其擅长HTTP工具开发——过去我曾多次利用Go优秀的&lt;code&gt;net/http/httputil.ReverseProxy&lt;/code&gt;处理器&lt;/p&gt;
&lt;p&gt;构建HTTP代理。&lt;a href="https://github.com/wazero/wazero"&gt;我还在尝试&lt;/a&gt;wazero&lt;a href="https://github.com/simonw/research/tree/main/wasm-repl-cli"&gt;，这是Go强大且成熟的零依赖WebAssembly运行时，作为我持续寻找运行不受信任代码的理想沙箱的一部分。&lt;/a&gt;这是我使用该库的&lt;/p&gt;
&lt;p&gt;能够将Go二进制文件无缝集成到Python项目中，而终端用户完全无需考虑Go的存在——一切都能顺利运行——这感觉像是为我工具箱增添了一个宝贵工具。

标签：go、打包、项目、pypi、python、sqlite、datasette、AI辅助编程、uv&lt;code&gt;pip install&lt;/code&gt; and everything Just Works - feels like a valuable addition to my toolbox.&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/go"&gt;go&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/packaging"&gt;packaging&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/projects"&gt;projects&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/pypi"&gt;pypi&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/sqlite"&gt;sqlite&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/datasette"&gt;datasette&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai-assisted-programming"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/uv"&gt;uv&lt;/a&gt;&lt;/p&gt;</description><pubDate>Wed, 04 Feb 2026 14:59:47 +0000</pubDate></item><item><title>Deno 沙盒环境介绍</title><link>https://simonwillison.net/2026/Feb/3/introducing-deno-sandbox/#atom-everything</link><description>&lt;p&gt;&lt;strong&gt;&lt;a href="https://deno.com/blog/introducing-deno-sandbox"&gt;Deno沙盒发布&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;Deno团队推出了一款新的托管沙盒产品。它实际上与Deno本身无关——这是他们Deno Deploy SaaS平台的一部分。因此，你甚至不需要使用JavaScript来访问它——你可以使用他们的&lt;a href="https://pypi.org/project/deno-sandbox/"&gt;deno-sandbox&lt;/a&gt;Python库在托管沙盒中创建和执行代码，如下所示：
&lt;div class="highlight highlight-source-shell"&gt;&lt;pre&gt;&lt;span class="pl-k"&gt;export&lt;/span&gt; DENO_DEPLOY_TOKEN=&lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;... API令牌 ...&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt;
uv run --with deno-sandbox python&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后：&lt;/p&gt;
&lt;pre&gt;&lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s1"&gt;deno_sandbox&lt;/span&gt; &lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-v"&gt;DenoDeploy&lt;/span&gt;

&lt;span class="pl-s1"&gt;sdk&lt;/span&gt; &lt;span class="pl-c1"&gt;=&lt;/span&gt; &lt;span class="pl-en"&gt;DenoDeploy&lt;/span&gt;()

&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-s1"&gt;sdk&lt;/span&gt;.&lt;span class="pl-c1"&gt;sandbox&lt;/span&gt;.&lt;span class="pl-c1"&gt;create&lt;/span&gt;() &lt;span class="pl-k"&gt;as&lt;/span&gt; &lt;span class="pl-s1"&gt;sb&lt;/span&gt;:
    &lt;span class="pl-c"&gt;# 运行shell命令&lt;/span&gt;
    &lt;span class="pl-s1"&gt;process&lt;/span&gt; &lt;span class="pl-c1"&gt;=&lt;/span&gt; &lt;span class="pl-s1"&gt;sb&lt;/span&gt;.&lt;span class="pl-c1"&gt;spawn&lt;/span&gt;(
        &lt;span class="pl-s"&gt;"echo"&lt;/span&gt;, &lt;span class="pl-s1"&gt;args&lt;/span&gt;&lt;span class="pl-c1"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;"Hello from the sandbox!"&lt;/span&gt;]
    )
    &lt;span class="pl-s1"&gt;process&lt;/span&gt;.&lt;span class="pl-c1"&gt;wait&lt;/span&gt;()
    &lt;span class="pl-c"&gt;# 写入和读取文件&lt;/span&gt;
    &lt;span class="pl-s1"&gt;sb&lt;/span&gt;.&lt;span class="pl-c1"&gt;fs&lt;/span&gt;.&lt;span class="pl-c1"&gt;write_text_file&lt;/span&gt;(
        &lt;span class="pl-s"&gt;"/tmp/example.txt"&lt;/span&gt;, &lt;span class="pl-s"&gt;"Hello, World!"&lt;/span&gt;
    )
    &lt;span class="pl-en"&gt;print&lt;/span&gt;(&lt;span class="pl-s1"&gt;sb&lt;/span&gt;.&lt;span class="pl-c1"&gt;fs&lt;/span&gt;.&lt;span class="pl-c1"&gt;read_text_file&lt;/span&gt;(
        &lt;span class="pl-s"&gt;"/tmp/example.txt"&lt;/span&gt;
    ))&lt;/pre&gt;
&lt;p&gt;还有一个JavaScript客户端库。底层API尚未文档化，但似乎&lt;a href="https://tools.simonwillison.net/zip-wheel-explorer?package=deno-sandbox#deno_sandbox/sandbox.py--L187"&gt;使用WebSockets&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;这个系统有很多值得称道的地方。沙盒实例最多可拥有4GB内存，配备2个vCPU，10GB临时存储，可以挂载持久卷，并且可以使用快照快速启动预配置的自定义镜像。会话最长可持续30分钟，按CPU时间、内存GB-小时和卷存储使用量计费。&lt;/p&gt;
&lt;p&gt;创建沙盒时，你可以配置允许访问的网络域。&lt;/p&gt;
&lt;p&gt;我最喜欢的功能是它处理API密钥的方式。&lt;/p&gt;
&lt;pre&gt;&lt;span class="pl-k"&gt;with&lt;/span&gt; &lt;span class="pl-s1"&gt;sdk&lt;/span&gt;.&lt;span class="pl-c1"&gt;sandboxes&lt;/span&gt;.&lt;span class="pl-c1"&gt;create&lt;/span&gt;(
    &lt;span class="pl-s1"&gt;allowNet&lt;/span&gt;&lt;span class="pl-c1"&gt;=&lt;/span&gt;[&lt;span class="pl-s"&gt;"api.openai.com"&lt;/span&gt;],
    &lt;span class="pl-s1"&gt;secrets&lt;/span&gt;&lt;span class="pl-c1"&gt;=&lt;/span&gt;{
        &lt;span class="pl-s"&gt;"OPENAI_API_KEY"&lt;/span&gt;: {
            &lt;span class="pl-s"&gt;"hosts"&lt;/span&gt;: [&lt;span class="pl-s"&gt;"api.openai.com"&lt;/span&gt;],
            &lt;span class="pl-s"&gt;"value"&lt;/span&gt;: &lt;span class="pl-s1"&gt;os&lt;/span&gt;.&lt;span class="pl-c1"&gt;environ&lt;/span&gt;.&lt;span class="pl-c1"&gt;get&lt;/span&gt;(&lt;span class="pl-s"&gt;"OPENAI_API_KEY"&lt;/span&gt;),
        }
    },
) &lt;span class="pl-k"&gt;as&lt;/span&gt; &lt;span class="pl-s1"&gt;sandbox&lt;/span&gt;:
    &lt;span class="pl-c"&gt;# ... $OPENAI_API_KEY 可用&lt;/span&gt;&lt;/pre&gt;
&lt;p&gt;在容器内部，&lt;code&gt;$OPENAI_API_KEY&lt;/code&gt;该值被设置为类似这样的形式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DENO_SECRET_PLACEHOLDER_b14043a2f578cba...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;发往&lt;code&gt;api.openai.com&lt;/code&gt;的API调用会经过一个代理，该代理知道这些占位符并将其替换为原始密钥。&lt;/p&gt;
&lt;p&gt;这样，密钥本身对沙盒内的代码不可用，从而限制了恶意代码（例如来自提示注入）窃取这些密钥的能力。&lt;/p&gt;
&lt;p&gt;从&lt;a href="https://news.ycombinator.com/item?id=46874097#46874959"&gt;Hacker News的一条评论&lt;/a&gt;中，我了解到Fly有一个名为&lt;a href="https://github.com/superfly/tokenizer"&gt;tokenizer&lt;/a&gt;的项目，实现了相同的模式。这已加入我在沙盒环境中使用的技巧清单！&lt;p&gt;&lt;small&gt;&lt;/small&gt;通过&lt;a href="https://news.ycombinator.com/item?id=46874097"&gt;Hacker News&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/python"&gt;python&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/sandboxing"&gt;sandboxing&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/security"&gt;security&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/deno"&gt;deno&lt;/a&gt;、&lt;a href="https://simonwillison.net/tags/fly"&gt;fly&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;</description><pubDate>Tue, 03 Feb 2026 22:44:50 +0000</pubDate></item><item><title>一月赞助者专属通讯已发布</title><link>https://simonwillison.net/2026/Feb/3/january/#atom-everything</link><description>&lt;p&gt;我刚刚发送了&lt;a href="https://github.com/sponsors/simonw/"&gt;仅供赞助者阅读的月度通讯一月刊&lt;/a&gt;。如果您已是赞助者（或立即开启赞助），可以&lt;a href="https://github.com/simonw-private/monthly/blob/main/2026-01-january.md"&gt;点击此处查看&lt;/a&gt;。本期一月通讯内容包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2026年大语言模型发展预测&lt;/li&gt;
&lt;li&gt;编程智能体持续引发关注&lt;/li&gt;
&lt;li&gt;Clawdbot/Moltbot/OpenClaw实现现象级传播&lt;/li&gt;
&lt;li&gt;鸮鹦鹉繁殖季迎来强势开局&lt;/li&gt;
&lt;li&gt;沙盒环境新增多项选择&lt;/li&gt;
&lt;li&gt;浏览器成为编程智能体集群的"Hello World"&lt;/li&gt;
&lt;li&gt;Sam Altman探讨软件工程的杰文斯悖论&lt;/li&gt;
&lt;li&gt;模型发布与多元附加内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;您可通过&lt;a href="https://gist.github.com/simonw/13e595a236218afce002e9aeafd75cd0"&gt;十二月通讯副本&lt;/a&gt;预览往期内容。每月支付10美元即可提前一个月获取付费资讯！&lt;/p&gt;
&lt;p&gt;标签：&lt;a href="https://simonwillison.net/tags/newsletter"&gt;通讯简报&lt;/a&gt;&lt;/p&gt;</description><pubDate>Tue, 03 Feb 2026 06:36:10 +0000</pubDate></item><item><title>引用布兰登·桑德森</title><link>https://simonwillison.net/2026/Feb/3/brandon-sanderson/#atom-everything</link><description>&lt;blockquote cite="https://www.youtube.com/watch?v=mb3uK-_QkOo&amp;amp;t=832s"&gt;&lt;p&gt;这就是数据与大型语言模型之间的区别——至少是目前正在运行的这些模型。数据创作艺术是因为它渴望成长，渴望成为某种存在，渴望理解。艺术是我们成为理想自我的途径。[...]

书籍、绘画、电影剧本并非艺术的唯一形式。它们固然重要，但在某种意义上，它们更像是收据或文凭。你写的书、创作的画、谱写的音乐固然重要且富有艺术性，但它们更是你完成学习过程的证明。因为归根结底，你本身就是艺术品。艺术创作带来的最重要改变，是发生在你内心的蜕变。最重要的情感，是你在书写故事时、在捧起完成作品时体验到的悸动。我不在乎人工智能能否创造出比人类更优秀的作品，因为它永远不会被自己的创作所改变。

——  
布兰登·桑德森  
经由  
吉多·范罗苏姆  
标签：  
人工智能伦理，  
生成式人工智能，  
艺术，  
人工智能，  
大语言模型，  
吉多·范罗苏姆&lt;/p&gt;
&lt;p&gt;The book, the painting, the film script is not the only art. It's important, but in a way it's a receipt. It's a diploma. The book you write, the painting you create, the music you compose is important and artistic, but it's also a mark of proof that you have done the work to learn, because in the end of it all, you are the art. The most important change made by an artistic endeavor is the change it makes in you. The most important emotions are the ones you feel when writing that story and holding the completed work. I don't care if the AI can create something that is better than what we can create, because it cannot be changed by that creation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p class="cite"&gt;— &lt;a href="https://www.youtube.com/watch?v=mb3uK-_QkOo&amp;amp;t=832s"&gt;Brandon Sanderson&lt;/a&gt;, via &lt;a href="https://x.com/gvanrossum/status/2018491452771418402"&gt;Guido van Rossum&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tags: &lt;a href="https://simonwillison.net/tags/ai-ethics"&gt;ai-ethics&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/generative-ai"&gt;generative-ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/art"&gt;art&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/ai"&gt;ai&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/llms"&gt;llms&lt;/a&gt;, &lt;a href="https://simonwillison.net/tags/guido-van-rossum"&gt;guido-van-rossum&lt;/a&gt;&lt;/p&gt;</description><pubDate>Tue, 03 Feb 2026 02:31:10 +0000</pubDate></item></channel></rss>